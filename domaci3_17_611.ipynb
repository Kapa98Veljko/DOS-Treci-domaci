{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><span style=\"color:yellow\">Treci domaci iz Digitalne obrade slike<span><center>\n",
    "###  <span style=\"color:blue\">Student       : Veljko Ilic<span>\n",
    "    \n",
    "###  <span style=\"color:blue\">Br. indeksa   : 2017/0611<span> \n",
    "    \n",
    "###  <span style=\"color:blue\">Datum predaje : 3.12.2022>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Celija koda ispod poziva sve potrebne biblioteke koje se koriste u izradi zadataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from scipy import *\n",
    "from pylab import *\n",
    "\n",
    "plt.style.use('dark_background');\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "import skimage\n",
    "from skimage import *\n",
    "from skimage import color\n",
    "from skimage import exposure\n",
    "from skimage import filters\n",
    "from skimage import feature\n",
    "from skimage import io\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadatak 1.1 <span style=\"color:yellow\"><center>Implementacija Canny-jevog algoritma za detekciju ivica<center><span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri realizacij Kanijevog algoritma prva stvar koja se proveri jeste da li su prosledjeni podaci ispravni ili ne i ispit odgovarajuce poruke.Zatim je primenjen Gausov filtar kako bi se ocistio sum i da se ostri prelazi ispeglaju. Nakon toga ono sto sam uradio jeste da sam definisao Sobelov gradijentni operator i njega primenio po ***x*** i ***y*** koordinati ulazne slike.Slika na kojoj cu da testiram jeste slika broj tri.Ispod se nalazi rezultat prolaska Sobelovim operatorom za razlicite vrednosti sigma.Ono sto moze da se vidi iz prilozenog jeste da se sto vise smanjujem ***sigma*** blurovanje slike je manje pa su samim tim i ivice brojeva i kazaljku ostrije odnosno sto je sigma manje vise detalja izlazi u prvi plan.Kako se ***sigma*** poveca ivice postaju masnije tj. razlivenije.\n",
    "\n",
    ">sigma = 2:\n",
    "    >>![clock3](sekvence/canny1.jpg)\n",
    "    \n",
    "\n",
    ">sigma = 1:\n",
    "    >>![clock3](sekvence/canny2.jpg)\n",
    "    \n",
    "    \n",
    ">sigma = 0.4:\n",
    "    >>![clock3](sekvence/canny3.jpg)   \n",
    "\n",
    "\n",
    "Sto se tice kvantizacije uglova na jedan od cetiri pravaca tu nemam sta posebno da naglasi sem da je to sekvenca ***if*** uslova.Kada se odredi u kom pravcu se prostire ivica samo ispitam da li je trenutni piksel najveceg inteziteta u tom pravcu ako jeste onda se sadrzava u suprotnom se postavalja na nuli. To se naravno vrsi na novoj matrici koja posle obrade potiskivanja ne-lokalnih maksimuma sadrzi ivice izdvojene sa slike ali su sada te ivice debljine jednog piksela. \n",
    "Ovde cu uporedno prikazati i kako izgleda kada se potisnu ne-lokalni maksimumi i kada se odbace ivice razdvoje na slabe i jake.Dakle to mi je samo jos jedan for petlja koja za izdvojene ivice koje su izmedju gornjeg i donjeg praga racuna da li u susedstvu ima bar jedan pikesl vrednosti 1 i ako da onda i njemu dodeljuje vrednost jedan.Evo i par primera za ***sigma=0.8***,i razlicito ***treshol_low***,***treshold_high**. Nije da primecujem neku znacajno veliku razliku za malu pormenu vrednosti viseg praga, mozda je po meni samo obod sata manje izreckan, ali svakako je bitno da je sada slika sastavljena samo od 0 i 1.To kazem jer moze se primetiti da je slika svetlija, a to iz iz razloga sto kada se racunaju magnituda spektra i ugao vrednosti su u float poin.    \n",
    "\n",
    ">sigma = 0.8,treshold_low = 0.2, treshold_high=0.55:\n",
    "    >>![clock3](sekvence/canny4.jpg)\n",
    "    \n",
    "    \n",
    ">sigma = 0.8, treshold_low = 0.2, treshold_high=0.75:\n",
    "    >>![clock3](sekvence/canny5.jpg)   \n",
    "\n",
    "\n",
    "Vidzeti su zakomentarisani kao i prikaz rezultata, dakle funkcija pri svom radu nece prikazivati nikakve rezultate vec samo vraca detektovane ivice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detector(img_in,sigma_,treshold_low,treshold_high):\n",
    "    '''\n",
    "    \"Canny Edge Detector implementation\"\n",
    "    __Author__--Veljko Ilic, veljkoilic86@gmail.com\n",
    "    \n",
    "    Ova funkcija za ulaznu sliku vrsi izdvajanje njenih ivica pomocu Kanijevog algoritma.Pored slike koja treba da bude\n",
    "    obradjena funkciji se prosledjuju i standardan devijacija Gausovog suma, vrednost nizeg prada i vrednost viseg praga.\n",
    "    \n",
    "    Inputs\n",
    "    img_in        - siva slika na kojoj treba detektovati ivice\n",
    "    sigma         - standardna devijacija Gausovog suma\n",
    "    treshold_low  - gornja vrednost praga za detekciju jakih ivica\n",
    "    treshold_high - donja vrednost praga za odbacijvanje slabih ivica\n",
    "    \n",
    "    Outputs\n",
    "    img_canny - izdvojene ivice sa ulazne slike debljine jedan piksel     \n",
    "    \n",
    "    Example\n",
    "    img_edges = canny_edge_detector(img_in,0.2,0.2,0.3)\n",
    "    '''\n",
    "    \n",
    "    #Evaluating input data\n",
    "    if(treshold_low<0):\n",
    "        print('treshold_low has to be positive number!');\n",
    "        return False;\n",
    "    if(treshold_high<0):\n",
    "        print('treshold_high has to be positive number!');\n",
    "        return False;\n",
    "    if(treshold_high<treshold_low):\n",
    "        print('treshold_high can not be less then treshold_low!');\n",
    "        return False;\n",
    "    if(sigma_<0):\n",
    "        print('std has to be positive number!');\n",
    "        return False;\n",
    "    \n",
    "    #Noise Reduction of input image with Gaussian filter,radius=3\n",
    "    img_gauss = skimage.filters.gaussian(img_in, sigma=sigma_, mode='nearest', truncate=3/sigma_);\n",
    "    \n",
    "    #Sobel gradient operator\n",
    "    Hx=np.array([[-1,-2,-1],[0,0,0],[1,2,1]]);\n",
    "    Hy=np.transpose(Hx);\n",
    "\n",
    "    Gx=scipy.ndimage.convolve(img_gauss, Hx, mode='nearest');\n",
    "    Gy=scipy.ndimage.convolve(img_gauss, Hy, mode='nearest');\n",
    "    \n",
    "    #Angle and Magnitude\n",
    "    mag = np.sqrt(np.square(Gx) + np.square(Gy));\n",
    "    angle=np.rad2deg(np.arctan2(Gy,Gx));\n",
    "    \n",
    "    #figure, ax=subplots(nrows=1, ncols=4, figsize=(12,4), dpi=80);\n",
    "\n",
    "    #ax[0].imshow(image, cmap='gray', vmin=0, vmax=1), ax[0].set_title('Originalna slika'), ax[0].axis('off')\n",
    "    #ax[1].imshow(image, cmap='gray', vmin=0, vmax=1), ax[1].set_title('Blurovana slika'), ax[1].axis('off')\n",
    "\n",
    "    #ax[2].imshow(Gx, cmap='gray', vmin=amin(Gx), vmax=amax(Gx)), ax[2].set_title('Horizontalne ivice -\\nvertikalni gradijent')\n",
    "    #ax[2].axis('off')\n",
    "\n",
    "    #ax[3].imshow(Gy, cmap='gray', vmin=amin(Gy), vmax=amax(Gy)), ax[3].set_title('Vertikalne ivice -\\nhorizontalni gradijent')\n",
    "    #ax[3].axis('off')\n",
    "\n",
    "    #matplotlib.pyplot.tight_layout()\n",
    "    #plt.show();\n",
    "\n",
    "    #figure, ax=subplots(nrows=1, ncols=2, figsize=(15,6), dpi=80);\n",
    "    #ax[0].imshow(mag, cmap='gray', vmin=0, vmax=1), ax[0].set_title('Magnituda gradijenta'), ax[0].axis('off');\n",
    "    #im = ax[1].imshow(angle, cmap='jet')\n",
    "    #ax[1].set_title('Ugao gradijenta'), ax[1].axis('off');\n",
    "    #figure.colorbar(im, ax=ax[1], fraction=0.04, pad=0.08);\n",
    "\n",
    "\n",
    "    #Determening compas regions\n",
    "    [height,width]= img_in.shape;\n",
    "    img_non_max=np.zeros(img_in.shape);\n",
    "\n",
    "    for i in range(1,height-1):\n",
    "        for j in range(1,width-1):\n",
    "            q=0;\n",
    "            r=0;\n",
    "\n",
    "            #Horizontal edge\n",
    "            if((angle[i,j]>=-22.5 and angle[i,j]<=22.5) or (angle[i,j]>=157.5 and angle[i,j]<= -157.5)):\n",
    "                q = mag[i-1,j]\n",
    "                r = mag[i+1,j]\n",
    "            #-45 degre edge    \n",
    "            elif((angle[i,j]>22.5 and angle[i,j]<=67.5) or (angle[i,j]> -157.5 and angle[i,j]<= -112.5)):  \n",
    "                q = mag[i-1,j-1]\n",
    "                r = mag[i+1,j+1]\n",
    "            #Vertical edge    \n",
    "            elif((angle[i,j]>67.5 and angle[i,j]<=112.5) or (angle[i,j]> -112.5 and angle[i,j]<= -67.5)):  \n",
    "                q = mag[i,j-1]\n",
    "                r = mag[i,j+1]\n",
    "            #45 degre edge    \n",
    "            else:\n",
    "                q = mag[i-1,j+1]\n",
    "                r = mag[i+1,j-1]\n",
    "             \n",
    "            if(mag[i,j] > q and mag[i,j] > r):\n",
    "                img_non_max[i,j] = mag[i,j];\n",
    "                \n",
    "    #figure, ax=subplots(nrows=1,ncols=2,figsize=(12,6), dpi=80);\n",
    "    #ax[0].imshow(img_non_max, cmap='gray', vmin=0, vmax=1), ax[0].set_title('Potisnuti ne-lokalni maksimumi')\n",
    "    #ax[0].axis('off');\n",
    "                \n",
    "    #Histerezis tresholding\n",
    "    tr_low  = treshold_low*np.max(img_non_max)\n",
    "    tr_high = treshold_high*np.max(img_non_max)   \n",
    "    \n",
    "    #New image with same size\n",
    "    img_canny = np.zeros(img_in.shape);\n",
    "    \n",
    "    #Determ. weak and strong edges.Also zero edges. \n",
    "    strong_i, strong_j = np.where(img_non_max>tr_high);\n",
    "    weak_i,   weak_j   = np.where((img_non_max>=tr_low) & (img_non_max<=tr_high));\n",
    "    zeros_i,  zeros_j  = np.where(img_non_max<tr_low); \n",
    "    \n",
    "    img_canny[strong_i,strong_j] = 1;\n",
    "    \n",
    "    #Wheater weak edge is conected to strong or it si not an edge at all.\n",
    "    for i in range(0,weak_i.size-1):\n",
    "        if(img_non_max[weak_i[i]-1][weak_j[i]]==1 or img_non_max[weak_i[i]+1][weak_j[i]]==1 or\\\n",
    "          img_non_max[weak_i[i]][weak_j[i]-1]==1 or img_non_max[weak_i[i]][weak_j[i]+1]==1 or\\\n",
    "          img_non_max[weak_i[i]-1][weak_j[i]-1]==1 or img_non_max[weak_i[i]+1][weak_j[i]-1]==1 or\\\n",
    "          img_non_max[weak_i[i]-1][weak_j[i]+1]==1 or img_non_max[weak_i[i]+1][weak_j[i]+1]==1):\n",
    "            \n",
    "            img_canny[weak_i[i]][weak_j[i]]=1;\n",
    "            \n",
    "    #Ploting result\n",
    "    #ax[1].imshow(img_canny, cmap='gray', vmin=0, vmax=1), ax[1].set_title('Double Histerezis')   \n",
    "     \n",
    "       \n",
    "    return img_canny;    \n",
    "#data_dir = 'sekvence/clocks/';\n",
    "#Ovo je kul stvar ovaj as_gray!!! ali mora da ide pre toga io.imread\n",
    "#image = skimage.img_as_float((io.imread(os.path.join(data_dir, 'clock3.png'),as_gray=True)));\n",
    "#img_canny = canny_edge_detector(image,5,0,0)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interact(canny_edge_detector, img_in = fixed(image), sigma_ = (0,5,0.1), treshold_low=(0,0.8,0.02), treshold_high=(0,0.8,0.05));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadatak 1.2 <span style=\"color:yellow\"><center>Implementacija funkcije ***get_line_segments***<center><span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementacija funkcije ***get_line_segments*** koristi pomocnu funkciju ***chechSurrounding*** koja proverava lokalno susedstvo piksela koji se trenutno obradjuje.Nacin na koji sam ja realizovao resenje jeste da kada se dobiju uglovi i normalno rastojanje $(\\rho,\\theta)$ pomocu ugradjene funkcije **transform_hough_line** ja mogu iz jednacine $\\rho=y*sin(\\theta)+x*cos(\\theta)$ da izrazim $y$ ili $x$.Sada recimo izrazim $y=\\frac{\\rho-x*cos(\\theta)}{sin(\\theta)}$ i kako mogu da dobijem jako lako sirinu slike onda za svaku vrednost $x$ iz opsega od nula do sirina slike mogu da dobijem koliko iznosi $y$. Ovo mi je bitno jer ja sada znam koji pikseli pripadaju pravi koju je detektovala ugradjena funkcija. Dalje kako znam koji pikseli pripadaju detektovanim pravama ja mogu da prodjem kroz sliku i da uporedim da li se na pozicijama koje pripadaju dobijenom pravu postoje i pikseli koji imaju vrednost jedan, ako postoji barem jedan krece se detekcijom duzi na datoj pravoj. Kako su pozicije piksela celi brojevi onda se moze desiti da li zbog zaokruzivana da piksel nije bas na mestu na kom se ocekuje pa se zato koristi ugradjena funkcija ***checkSurrounding*** koja proverava okolinu koja se zadaje parametrom **tolerancy**.Ako je prekid veci od dozvoljene vrednosti parametrom **max_gaps** onda se ispita da li je linija detektovana manja od duzine zadate parametrom **line_size**, ako nije onda se koordinate pocetka i kraja vracaju kao povratna vrednost funkcije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSurrounding(img_in,tolerancy,x,y):\n",
    "    if(img_in[y][x]==1):\n",
    "        img_in[y][x]=0;\n",
    "        return True;\n",
    "    else:\n",
    "        x1 = 0;y1 = 0;\n",
    "        if((x - tolerancy)>=0):\n",
    "            x1 = x - tolerancy;\n",
    "            \n",
    "        x2 = x + tolerancy+1;\n",
    "        if(x2>=img_in.shape[1]):\n",
    "            x2 = img_in.shape[1]-1;\n",
    "        \n",
    "        if((y - tolerancy)>=0):\n",
    "            y1 = y - tolerancy;\n",
    "        \n",
    "        y2 = y + tolerancy+1;\n",
    "        if(y2>=img_in.shape[0]):\n",
    "            y2 = img_in.shape[0]-1;\n",
    "        \n",
    "        for i in range(y1,y2):\n",
    "            for j in range(x1,x2):\n",
    "                if(img_in[i][j]==1):\n",
    "                    img_in[i][j]=0;\n",
    "                    return True;\n",
    "        return False;        \n",
    "\n",
    "def get_line_segments(img_edges,line,min_size,max_gaps,tolerancy):\n",
    "    '''\n",
    "    \"Canny Edge Detector implementation\"\n",
    "    __Author__--Veljko Ilic, veljkoilic86@gmail.com\n",
    "    \n",
    "    Ova funkcija za ulaznu sliku vrsi izdvajanje njenih ivica pomocu Kanijevog algoritma.Pored slike koja treba da bude\n",
    "    obradjena funkciji se prosledjuju i standardan devijacija Gausovog suma, vrednost nizeg prada i vrednost viseg praga.\n",
    "    \n",
    "    Inputs\n",
    "    img_edges – slika sa detektovanim ivičnim pikselima sa koje se detektuju linije\n",
    "    line      – niz od dva elementa (theta, rho) kojim se zadaje pravac linije\n",
    "    min_size  – minimalna dužina segmenta (u pikselima) da bi duž bila detektovana, sve\n",
    "                linije koje su manje od ove veličine treba da budu ignorisane. Povratni argument ove\n",
    "                funkcije su sve duži čija je dužina veća od ovog parametra\n",
    "    max_gaps  – maksimalne veličine prekida (u pikselima) koje se mogu ignorisati prilikom\n",
    "                detekcije duži\n",
    "    tolerancy – radijus okoline u okviru koje se traže ivični pikseli\n",
    "    \n",
    "    Outputs\n",
    "    line_segments - izdvojene ivice sa ulazne slike debljine jedan piksel     \n",
    "    \n",
    "    Example\n",
    "    img_edges = canny_edge_detector(img_in,0.2,0.2,0.3)\n",
    "    '''\n",
    "    #Evaluating if input data is correct\n",
    "    if(line.size==0 or line.size==1):\n",
    "        print(\"Morate proslediti i theta i ro parametar koji odredjuju duz!\");\n",
    "        return False;\n",
    "    if(min_size<=0):\n",
    "        print(\"Minimalna duzina segmenta mora biti vece od nule!\");\n",
    "        return False;\n",
    "    if(max_gaps<0):\n",
    "        print(\"Maksimalna duzina prekida mora biti veca od nule!\");\n",
    "        return False;\n",
    "    if(tolerancy<0):\n",
    "        print(\"Maksimalna duzina prekida mora biti veca od nule!\");\n",
    "        return False;\n",
    "    #Creating empty list of line segments end points\n",
    "    line_segments = [];\n",
    "    \n",
    "    #x and y coordinates of line \n",
    "    x_ = np.arange(0,img_edges.shape[1]-1);\n",
    "    y_ = (line[1] - x_*np.cos(line[0]))/np.sin(line[0])\n",
    "    \n",
    "    corr_val = np.where((y_>=0) & (y_<=img_edges.shape[0]))\n",
    "    \n",
    "    x = x_[corr_val];\n",
    "    y = y_[corr_val].astype(int);\n",
    "    \n",
    "    if(int(np.rad2deg(line[0]))==0):\n",
    "        x = np.zeros(img_edges.shape[0]-1);\n",
    "        y = np.arange(0,img_edges.shape[0]-1);\n",
    "        x += int(line[1])+1;\n",
    "        x = x.astype(int)\n",
    "    \n",
    "    begin = -1; \n",
    "    end = -1;\n",
    "    \n",
    "    line_length = 0;\n",
    "    gap_length = 0;\n",
    "    \n",
    "    for i in range(x.size-1):\n",
    "        #Does corresponding pixel exists\n",
    "        if(checkSurrounding(img_edges,tolerancy,x[i],y[i])):\n",
    "            #If it's a first dot on a line    \n",
    "            if(begin==-1):\n",
    "                begin=i;\n",
    "                continue;\n",
    "            if(gap_length<max_gaps):\n",
    "                line_length = np.sqrt((y[i]-y[begin])**2 + (x[i]-x[begin])**2);\n",
    "                end = i;\n",
    "                gap_length = 0;\n",
    "            else:\n",
    "                if(line_length>=min_size):\n",
    "                    line_segments.append((x[begin],y[begin]))\n",
    "                    line_segments.append((x[end],y[end]));\n",
    "                line_length = 0;\n",
    "                begin = -1;\n",
    "                end = -1;\n",
    "                gap_length = 0;\n",
    "        else:\n",
    "            if(begin!=-1):\n",
    "                gap_length += 1; \n",
    "                       \n",
    "    \n",
    "    return np.asarray(line_segments);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:yellow\"><center>Implementacija funkcije ***extract_time***<center><span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ova funkcija jeste da treba da prima razlicite slike ali sam je napravio da prima samo sivu sliku, odnosno kada se ova funkcija poziva odmah se vrsi ucitavanje slike kao sive. Prolazi se kroz sve prave koje detektuje Hafova transforamcija i dalje se prosledjuje **get_line_segment** pomocu koje se izdvajaju kazaljke. Zelim da pnapomenem da  je meni ugao pod kojim se traze kazaljke od $-\\pi$ do $\\pi$ jer za casovniksa slike 1 u suprotno ne detektuje kazaljku za sate.Kako su se neke kazaljke na casovnicima duplirale kada sam povecao ovaj ugao onda sam morao da kada se pomocu ***get_line_segments*** da proverim da li sam vec pod slicnim uglom(tj sa odredjenim odstupanjem od 5 stepeni) vec detektovao kazaljku. Tako da je meni svaka kazaljka kada je iscrtavam detektovana samo sa jednom crvenom linijom.\n",
    "\n",
    "Prvi parametar koji je bilo tesko izbrati jeste sigma, jer iako se vidi da je u delu gde je implementiran Kanije algoritam da sto je sigma manje ivice bivaju ostrije medjutim to ovde kod detekcije ivica nije najpametnije jer sto je ugao ostriji i nije ceo npr 22.5 stepeni kao na slici ispod kazaljka za sate ne moze biti detektovana.Mozda za vece sigma ivica broje izgledaju okrnjeno mejdjutim mi zelimo da detektujemo kazaljke a ne brojeve. I ovaj parametar je bilo najteze namestiti jer je trebalo naci sweet spot za sve casovnike. Parametar za minimalnu duzinu linije je 84 jer ako je ispod toga onda se ne moze detektovati kazaljka na casovniku 9.\n",
    "\n",
    ">cloclk1, sigma = 0.4,\n",
    "    >>![clock1](sekvence/clock1sigma=0.4.jpg)\n",
    "    \n",
    ">clokc1, sigma = 1.75,\n",
    "    >>![clock1s](sekvence/clock1sigma=1.8.jpg)    \n",
    "\n",
    ">sigma = 1.75, min_size=85,\n",
    "    >>![clock9](sekvence/clk9min_size=85.jpg) \n",
    "    \n",
    "Kada takodje tolerancy se ovde mora postaviti na 2 inace se ne detektuje kazaljka za sate.\n",
    ">sigma = 1.75, min_size=84,\n",
    "    >>![clock9s](sekvence/clk9min_size=84.jpg) \n",
    "    \n",
    "Ovaj proces je bio mucan dok nisam dosao do ovih nekih vrednosti pomocu kojih program radi ispravno tj. ispravno detektuje sate i minute.\n",
    "\n",
    "Dakle kada se detektuje duz ona se doda u niz koji sam nazvao ***data*** a gde se ubacuju ugao pod koji je kazaljka,region kome pripada i duzine iste.Ugao mi vraca ugradjena funkcija za Hafovu transformaciju, duzinu odredjujem kao Euklidsko rastojanje, a region se odredjuje na osnovu centra sata. Pored toga sam mora da tom centru sata dam ofset jer nije na svakoj slici tacno u centru i sada pomocu ovih parametara ja odredjujem koliko ima sati.Duza kazljka je za minute, kraca za sate. Ako se kazaljke nalaze u regionu tri ili 4 onda se ne broj sati, minuta dodaje 6 odnosno 30. Ako je detektovana samo jedna kazaljka onda se smara da su se preklopile. Evo par primera koji ilustruju ispravan rad programa.\n",
    "\n",
    ">Clock  1 time\n",
    "    >>![clock1time](sekvence/clk1time.jpg)\n",
    "    \n",
    ">Clock 5 time\n",
    "    >>![clock5time](sekvence/clk5.time.jpg)    \n",
    "\n",
    ">Clokc 6 time\n",
    "    >>![clock6time](sekvence/clk6time.jpg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time(img_in):\n",
    "    '''\n",
    "    \"Extract Time implementation\"\n",
    "    __Author__--Veljko Ilic, veljkoilic86@gmail.com\n",
    "    \n",
    "    Ova funkcija za ulaznu sliku poziva funkciju koja implementira Kanijev algoritam detekcije ivica i nakod toga se\n",
    "    pomocu ugradjene funkcije za hafovu transforamciju dobijaju detektovane ivice. Dalje obrada jeste izdvajanje kazaljki \n",
    "    sa sata i zatim odredjivanje koliko je sati.\n",
    "    \n",
    "    Inputs\n",
    "    img_in - slika sa koje je potrebno ocitati vreme\n",
    "    \n",
    "    Outputs\n",
    "    hourse,minute - povratna vresnot su sati i munti     \n",
    "    \n",
    "    Example\n",
    "    hours,minute - extract_time(img_in)\n",
    "    '''\n",
    "    #Canny edge detecting\n",
    "    img_edges = canny_edge_detector(img_in,1.75,0.3,0.5);\n",
    "    origin = np.array((0, img_in.shape[1]))\n",
    "    \n",
    "    #Haf transform for finding lines\n",
    "    [out, angles, distances] = skimage.transform.hough_line(img_edges,np.linspace(-np.pi,np.pi,360))\n",
    "    [intensity, peak_angles, peak_distances] = skimage.transform.hough_line_peaks(out, angles, distances, \\\n",
    "                                                                                threshold=None, num_peaks=9) \n",
    "    # plot detected lines\n",
    "    #fix, axes = plt.subplots(1, 1, figsize=(20, 8))\n",
    "    #axes.imshow(img_edges, cmap='gray')\n",
    "    #axes.set_title('Casovnik sa detektovanim kazaljkama.')\n",
    "    #axes.set_xlim(origin)\n",
    "    #axes.set_ylim((img_in.shape[0], 0))\n",
    "    #axes.axis('off');\n",
    "    #new array to store xbegin,xend,ybegin,yend\n",
    "    line_segments = np.zeros(4);\n",
    "    #array to store hours,minute,second\n",
    "    data = np.zeros((3,3))-1;\n",
    "    k = 0;\n",
    "    for _, angle,dist  in zip(intensity, peak_angles, peak_distances):\n",
    "        line = np.array([angle,dist])\n",
    "        line_segments =  get_line_segments(img_edges,line,min_size=84,max_gaps=1,tolerancy=2);\n",
    "        #Do the thing only if line is detected\n",
    "        if(line_segments.size!=0):\n",
    "            #So everything is between 0 and pi                   \n",
    "            angle = np.rad2deg(angle)\n",
    "            if(np.rad2deg(angle)<0):\n",
    "                angle += 180\n",
    "\n",
    "            found = False;\n",
    "            #check if there is same specification line already detected\n",
    "            for i in range(3):\n",
    "                if(np.abs(angle-data[i][0])<=5):\n",
    "                    found=True;\n",
    "                    break;\n",
    "            #If there is no two same elements        \n",
    "            if(not found):\n",
    "                #coord of begining and end\n",
    "                x_begin = line_segments[0][0]\n",
    "                x_end   = line_segments[1][0]\n",
    "                y_begin = line_segments[0][1]\n",
    "                y_end   = line_segments[1][1]\n",
    "                x_centre = img_edges.shape[1]//2;\n",
    "                y_centre = img_edges.shape[0]//2;\n",
    "                #region where line is detected\n",
    "                region = 0;\n",
    "                if(x_begin>x_centre-50 and x_begin<x_centre+50):\n",
    "                    if(y_end<y_centre):\n",
    "                        region = 1;\n",
    "                    else:\n",
    "                        region = 2;\n",
    "                elif((x_end>x_centre-50) and (x_end<x_centre+50)):\n",
    "                    if(y_begin<y_centre):\n",
    "                        region = 4;\n",
    "                    else:\n",
    "                        region = 3;\n",
    "                #array od (angle,region,length)\n",
    "                data[k][0] = angle;\n",
    "                data[k][1] = region;\n",
    "                data[k][2] = np.sqrt((y_end-y_begin)**2 + (x_end-x_begin)**2);\n",
    "                k +=1;\n",
    "                \n",
    "                #axes.plot((line_segments[0][0],line_segments[1][0]),(line_segments[0][1],line_segments[1][1]),'-r');\n",
    "    \n",
    "    hours_index = 0;\n",
    "    minute_index = 1;\n",
    "    if(data[1][0]==-1.0):\n",
    "        minute_index = hours_index;\n",
    "    else:\n",
    "        if(data[0][2]>data[1][2]):\n",
    "            hours_index = 1;\n",
    "            minute_index = 0;\n",
    "        if(data[2][0]!=-1):\n",
    "            if(data[2][2]>data[minute_index][2]):\n",
    "                minute_index = 2\n",
    "            elif(data[2][2]<data[hours_index][2]):\n",
    "                hours_index = 2;\n",
    "    #Determening time\n",
    "    hours  = data[hours_index][0]//30;       \n",
    "    minute  = data[minute_index][0]//6; \n",
    "    if(data[minute_index][1]>2):\n",
    "        minute += 30;\n",
    "    if(data[hours_index][1]>2):\n",
    "        hours +=6;\n",
    "        \n",
    "    if((data[hours_index][1]==1.0 or data[hours_index][1]==4) and (np.abs(data[hours_index][0]-180)<=5) ):\n",
    "        hours = 12;\n",
    "    if((data[minute_index][1]==1.0 or data[minute_index][1]==4) and (np.abs(data[minute_index][0]-180)<=2) ):\n",
    "         minute = 0;\n",
    "    #if(data[hours_index][0])\n",
    "    if(hours==0):\n",
    "        hours=12;\n",
    "    return hours,minute;\n",
    "\n",
    "data_dir = 'sekvence/clocks'\n",
    "\n",
    "for i in range(1,10):\n",
    "    name = 'clock';\n",
    "    if(i==7 or i==8):\n",
    "        name = name+str(i)+'.jpg';\n",
    "    else:\n",
    "        name = name+str(i)+'.png';\n",
    "    \n",
    "    image = skimage.img_as_float((io.imread(os.path.join(data_dir, name))));\n",
    "    image_gray = skimage.img_as_float((io.imread(os.path.join(data_dir, name),as_gray=True)))\n",
    "    hours,minute =  extract_time(image_gray);\n",
    "    \n",
    "    title = str(int(hours)) + ':' + str(int(minute))\n",
    "    fig, ax = plt.subplots(figsize = [12,6],dpi=100);\n",
    "    ax.imshow(image,cmap='jet');\n",
    "    ax.set_title(title), ax.axis('off')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadatak 2.1 <span style=\"color:yellow\"><center>Implementacija funkcije ***coin_mask***<center><span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U funkciji ***coin_mask*** se pre svega slika prevede u HSV kolor sistem iz razloga sto je pozadina upecatljivo zelena, a sa idejom da se pozadina na kojoj su novcici izdvoji na histogramu, a naravno ono sto nije pozadina hocu da proglasim da je novicic i tako kreiram masku koja se dalje salje funkciji za labeliranje regiona.Preko Hue ravni se dosta dobro moze izdvojiti pozadina.Sama implementacija nakon transfera slike u HSV kolor sistem takodje filtrira sliku filtrom 13X13 jer ako se dobro zagledate u sliku 9e bez tog filtra meni su novcici koji su previse osvetljeni u H ravni(predstavljeni crvenom bojom) prosarani tj, imaju na sebi i zeleno i crvene i narandzaste boje, a ja sam zeleo da kada detektujem neke regione oni budu uniformni nebitno sto je maska i za taj region sa flitrom 3X3 dobra.\n",
    "\n",
    ">Slika 6\n",
    ">>![coin_mask6](sekvence/coin_mask6.jpg)\n",
    "  \n",
    ">Slika 7\n",
    ">>![coin_mask7](sekvence/coin_mask7.jpg)\n",
    "\n",
    "\n",
    ">Slika 9e\n",
    ">>![coin_mask9er](sekvence/coin_mask9error.jpg)\n",
    "\n",
    ">Slika 9\n",
    ">>![coin_mask9](sekvence/coin_mask9.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_mask(img_in):\n",
    "    '''\n",
    "    \"Coin Mask implementation\"\n",
    "    __Author__--Veljko Ilic, veljkoilic86@gmail.com\n",
    "    \n",
    "    Funkcija koja na ocnovu ulazne slike pravi binarznu masku i to salje na izlaz.Fukcija detektuje koji su pikseli pozadine\n",
    "    ostalo proglasava za regione od interesa za dalju obradu.Detekcija pozadine se vrsi u HSV kolor sistemu.\n",
    "    \n",
    "    Inputs\n",
    "    img_in- Ulazna slika od koje treba napraviti binarnu masku\n",
    "    \n",
    "    Outputs\n",
    "    img_bin - Binarizovana slika gde su detektovani regioni oznaceni sa 1 a pozadina sa 0.     \n",
    "    \n",
    "    Example\n",
    "    img_bin = coin_mask(img_in)\n",
    "    '''\n",
    "    #Creating output matrix same saze as input image\n",
    "    img_bin = np.zeros(img_in.shape,dtype=uint8)\n",
    "    \n",
    "    #transfer to HSV\n",
    "    imgHSV = color.rgb2hsv(img_in);\n",
    "    imgH = scipy.ndimage.median_filter(imgHSV[:,:,0], size=(13,13), mode='reflect')\n",
    "    #Ploting results\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(15,5), dpi=80)\n",
    "    ax[0].imshow(image,cmap='jet'),ax[0].set_title('Originalna slika'), ax[0].axis('off')\n",
    "    ax[1].imshow(imgH,cmap='jet'),ax[1].set_title('H ravan ulazne slike'), ax[1].axis('off')\n",
    "    \n",
    "    #Otsu method for threshold value \n",
    "    thresh1 = skimage.filters.threshold_otsu(imgH.flatten())\n",
    "    thresh2 = 0.55;\n",
    "    \n",
    "    #Logical indexing \n",
    "    img_bin = ((imgH < thresh1) | (imgH>thresh2))\n",
    "    ax[2].imshow(img_bin,cmap='gray'),ax[2].set_title('Maska izdvojena sa H ravni'), ax[2].axis('off')\n",
    "    #Ploting histogram with threshold values\n",
    "    #fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,4), dpi=80)\n",
    "    ax[3].hist(imgH.flatten(), bins=256, color='b'), ax[3].set_facecolor('white');\n",
    "    ax[3].axvline(x=thresh1, color='r', linestyle='-');\n",
    "    ax[3].axvline(x=thresh2, color='r', linestyle='-');\n",
    "    ax[3].set_title('Histogram H ravni ulazne slika')\n",
    "    tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return img_bin.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'sekvence/coins/';\n",
    "\n",
    "name = 'coins'\n",
    "name += str(9)+'.jpg';\n",
    "\n",
    "image = skimage.img_as_float((io.imread(os.path.join(data_dir, name))));\n",
    "\n",
    "img_bin = coin_mask(image);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadatak 2.2 <span style=\"color:yellow\"><center>Implementacija funkcije ***bw_label***<center><span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sto se tice labeliranja regiona na kojima su novcici moja funkcija koristi jos dve pomocne funkcije ***conect8*** i ***updateEquivalencyList***.\n",
    "\n",
    "Pri prvom prolasku kroz sliku ispituje se piksel po piksel, ako piksle ima vrednost nula onda se njemu dodeljuje labela 1.Ako piksel ima vrednost jedan onda se njemu dodeli nova labela ako su svi okolni pikseli 0 odnosno pikseli pozadine.\n",
    "Okruzenje jednog piksela se odredjuje pomocu funkcije ***conect8*** koja ako su svi pikseli okruznja8 jednaki 0 vraca vr. Flase i dodoeljuje se nova labela. Ukoliko u okruznju postoje piskeli koji nisu 0 onda se ispita da li su njihove labele razlicite ako nisu razlicite onda se dodeli ta ista labela piksela iz okruzenja pikselu koji se obradjuje.\n",
    "\n",
    "Ako postoji min dve razlicite labele onda se poziva funkcija ***updateEquivalencyList*** koja update-uje labele koje se nalaze u list1 i list2. Update-ovanje labele se vrsi tako sto ako je potrebno spojiti a->b i taj par ne postoji u list1(gde treba ocekivati a), a u list2(treba ocekivat b) onda se dodatno ispita i da li mozda u list2 postoji a? Zasto se ispituje da li u list2 postoji a? Recimo da treba spojiti a->b, a da u list1 postoji c kojem je par a u list2 onda je potrebno spojiti i c i b. Kako bih objasnio ovo na primerima ja sam osmislio moju dosta manju sliku na kojoj sam pre svega i testirao svoj kod. Par primera:\n",
    "\n",
    ">Slika 6\n",
    ">>![demo](sekvence/modelreg.jpg)\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conect8(bw_img,i,j):\n",
    "    '''\n",
    "    \"Connect8 implementation\"\n",
    "    __Author__--Veljko Ilic, veljkoilic86@gmail.com\n",
    "    \n",
    "    Ovo je pomocna funkcija koja vrsi proveru da li se u susedstvu 8 nalaze pikseli koji nisu pozadina i te\n",
    "    izdvojene piksele vraca nazad.Ako je nasla piksele koji nisu pozadina found=True u suprotno je False.\n",
    "    \n",
    "    Inputs\n",
    "    bw_img   - matrica koja sadrizi labele dodeljenje do trenutnog piklse (i,j)    \n",
    "    (i,j)    - koordinate trenutnog piksela koji se obradjuje\n",
    "    \n",
    "    Outputs\n",
    "    found    - logicki bool tip\n",
    "    neighbor - niz od vrednosti piksela iz okruzenja koji nisu pozadinksi pikseli\n",
    "    \n",
    "    Example\n",
    "    found,neighborp = conect8(bw_img,i,j)\n",
    "    '''\n",
    "    neighbor = np.ones(4,dtype=np.uint16);  \n",
    "    if((j-1)>=0):\n",
    "        neighbor[0]  = bw_img[i][j-1];      #west pixel\n",
    "        if((i-1)>=0):                       #\n",
    "            neighbor[1] = bw_img[i-1][j-1]; #north-west pixel\n",
    "    if((i-1)>=0):                           #\n",
    "        neighbor[2] = bw_img[i-1][j];       #north pixel  \n",
    "        if((j+1)<bw_img.shape[1]):          #\n",
    "            neighbor[3] = bw_img[i-1][j+1]; #north-east pixel\n",
    "    #Sorting ascending\n",
    "    neighbor.sort();  \n",
    "    #Find if all sorounding pixels are backgorund\n",
    "    y = np.count_nonzero(neighbor==1);      \n",
    "    \n",
    "    found = False;\n",
    "    if(y!=4):\n",
    "        found = True;\n",
    "    \n",
    "    return found,neighbor[y:4];\n",
    "\n",
    "def updateEquivalencyList(neighbor,list1,list2):\n",
    "    '''\n",
    "    \"Updating Equivalency List implementation\"\n",
    "    __Author__--Veljko Ilic, veljkoilic86@gmail.com\n",
    "    \n",
    "    Funkcija koja vrsi update liste ekvialenija izmedju labela koje se dodeljenje odredjenim pikselima.Ova funkcija se \n",
    "    poziva samo onda kada u 8 okruzenju ima piksela koji nizu oznaceni sa 1 tj. nisu pozadina i kada su pikseli iz okruzenja\n",
    "    razliciti jedni od drugih. Kao povratnu vrednost salje update-ovane liste ekvivalencija.\n",
    "    \n",
    "    Inputs\n",
    "    neighbor  - pikseli iz okruzenja 8  \n",
    "    list1     - list1 predstavalja na koju se vrednost labele iz list2 slikaju\n",
    "    list2     - labele koje treba zameniti sa labelama iz list1\n",
    "    \n",
    "    Outputs\n",
    "    list1    - update-ovana lista1\n",
    "    list2    - update-ovana lista2 \n",
    "    \n",
    "    Example\n",
    "    list1, list2 = updateEquivalencyList(neighbor,list1,list2)\n",
    "    '''\n",
    "    #Go through array of pixels in neighbor.\n",
    "    for i in range(0,neighbor.size):\n",
    "        #if list1 is empty add new pair od labels in list1 and list2\n",
    "        if(len(list1)==0):\n",
    "            list1.append(neighbor[0]);\n",
    "            list2.append(neighbor[1]);\n",
    "        else:\n",
    "            #logical ooperators\n",
    "            found = False;\n",
    "            found_l1 = False;\n",
    "            index = 0;\n",
    "            found_l2 = False;\n",
    "            #examining if pair of labels alreay exists\n",
    "            for j in range(1,neighbor.size):\n",
    "                for i in range(0,len(list1)):\n",
    "                    if(list1[i]==neighbor[0] and list2[i]==neighbor[j]):\n",
    "                        found_l1 = True;\n",
    "                        break;\n",
    "                    #if there is no pair a->b, but there is b->c then conect a->c\n",
    "                    if(list2[i]==neighbor[0]):\n",
    "                        found_l2 = True;\n",
    "                        index = i;\n",
    "                        break;\n",
    "                #if pair doesn't exist than add it\n",
    "                if((not found_l1) and found_l2): \n",
    "                    for i in range(0,len(list1)):\n",
    "                        if(list1[i]==list1[index] and list2[i]==neighbor[j]):\n",
    "                            found = True;\n",
    "                    if(not found):\n",
    "                        list1.append(list1[index]);\n",
    "                        list2.append(neighbor[j]);\n",
    "                elif(not found_l1):\n",
    "                    list1.append(neighbor[0]);\n",
    "                    list2.append(neighbor[j]);\n",
    "                found    = False;\n",
    "                found_l1 = False;\n",
    "                found_l2 = False;\n",
    "    return list1,list2;\n",
    "\n",
    "def bw_label(img_bin):\n",
    "    '''\n",
    "    \"Connected-component labeling implementation\"\n",
    "    __Author__--Veljko Ilic, veljkoilic86@gmail.com\n",
    "    \n",
    "    Funkcija koja vrsi spajanje povezanih regiona u formaciji 8, dakle svi ivicni pikseli i oni dijagonalni se ispituju.\n",
    "    Funkciji mora biti prosledjena binazirovana slika.Odmah na pocetku ako je ulazna slika prosla proveru da li su parametri \n",
    "    dobri kreira se nova matrica u koju se smestaju labele.Pri prvom prolasku kroz sliku se za svaki piksel ispituje da li je \n",
    "    pozadina ili ne ako nije pozadina ona se taj piksel labelira.Nakon labeliranja svih piksela prolazi se i drugi put da se \n",
    "    iz tabele ekvivalencija izvrsi spajanje regiona. Nova matrica regiona se salje na izlaz. \n",
    "    Inputs\n",
    "    img_bin = binarizovana ulazna slika gde je 0 pozadina, a 1 region od interesa\n",
    "    \n",
    "    Outputs\n",
    "    bw_img - matrica koja sadrzi labele spojenih regiona    \n",
    "    \n",
    "    Example\n",
    "    bw_img = bw_label(img_bin)\n",
    "    '''\n",
    "    [height, width] = img_bin.shape;\n",
    "    if(height==0 or width==0):\n",
    "        print(\"Ovoj funkciji se prosledjuje slika kao matrica i mora imate ne-nultu visinu i sirinu!\");\n",
    "        return False;\n",
    "    if(np.unique(img_bin).size!=2):\n",
    "        print(\"Niste prosledili binarizovanu sliku.\");\n",
    "        return False;\n",
    "    \n",
    "    #Creating new matrix like input image to store labels,all background labels are one\n",
    "    #initialy set all to 1 but will be changed in for loops\n",
    "    bw_img = np.zeros(img_bin.shape,dtype=np.uint16)-1;\n",
    "    \n",
    "    #new label starts from 5 because background label is 1, increment by one if 8 neighbor is all zeros   \n",
    "    label = 2;\n",
    "    #list's of labels for conected regions\n",
    "    list1 = [];\n",
    "    list2 = [];\n",
    "    #Going through image matrix and labeling conected components\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "            #If pixel is zero than it is backgound and label is 1\n",
    "            if(img_bin[i][j]==0):\n",
    "                bw_img[i][j] = 1;\n",
    "            #If pixel is 1 determening label\n",
    "            else:\n",
    "                #Finding 8 connected pixels on image, found is True if at least one neighb. pixel is not 1\n",
    "                found ,neighbor = conect8(bw_img,i,j);\n",
    "                if(found):\n",
    "                    #If all sorounding pixels are same  than label is copied\n",
    "                    result = np.all(neighbor == neighbor[0])\n",
    "                    bw_img[i][j] = neighbor[0];\n",
    "                    #Else if at least one pixel is diferent update Eq list's\n",
    "                    if(result == False):\n",
    "                        updateEquivalencyList(neighbor,list1,list2);\n",
    "                else:\n",
    "                    #If all neigh. pixel's are one than create new label\n",
    "                    bw_img[i][j] = label;\n",
    "                    label += 1;\n",
    "                    \n",
    "    #Second pass through image to connect component labels\n",
    "    #bw[:] = bw_img[:]\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "            if(bw_img[i][j]!=1):\n",
    "                if(list2.count(bw_img[i][j])):\n",
    "                    index = list2.index(bw_img[i][j]);\n",
    "                    bw_img[i][j] = list1[index];\n",
    "    #print(\"Liste ekvivalencija\")\n",
    "    #print('list1')\n",
    "    #print(list1)\n",
    "    #print('list2')\n",
    "    #print(list2)\n",
    "    return bw_img;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_bin = np.array([[0,0,1,0,0,0,0,0,0,0,1,0,0,0],\n",
    "                    [1,1,1,1,0,0,0,0,1,1,1,1,1,0],\n",
    "                    [0,0,1,0,0,0,0,0,0,0,1,0,0,0],\n",
    "                    [0,0,0,0,1,1,0,0,0,0,1,0,0,0],\n",
    "                    [0,1,0,0,0,0,1,0,1,1,1,0,0,0],\n",
    "                    [0,0,0,0,1,1,0,0,0,0,0,0,0,0],\n",
    "                    [0,0,1,1,0,1,0,0,0,0,0,0,0,0]]);\n",
    "\n",
    "#img_bin = coin_mask(image);\n",
    "\n",
    "#bw,img_out = bw_label(img_bin);\n",
    "#print('Matrica regiona pre povezivanja')\n",
    "#print(bw)\n",
    "#fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,4),dpi=100);\n",
    "#ax[0].imshow(bw,cmap='jet'),ax[0].set_title('Slika pre drugog prolaska'),ax[0].axis('off');\n",
    "#ax[1].imshow(img_out,cmap='jet'),ax[1].set_title('Slika nakon povezivanja regiona'),ax[1].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadatak 2.3 <span style=\"color:yellow\"><center>Implementacija funkcije ***coin_classification***<center><span>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Tabel koja prikazuje broj novcica po klasama, odnosno da program pri klasifikaciji ne gresi u odnosu na stvarno stanje <center>\n",
    "\n",
    "|Slika              |Klasa 1            |Klasa 2               |Ukupno            |\n",
    "|-------------------|-------------------|----------------------|------------------|\n",
    "|      coins1       |        12         |        34            |       46         |\n",
    "|      coins2       |         4         |        19            |       23         |\n",
    "|      coins3       |        10         |         7            |       17         |\n",
    "|      coins4       |         7         |         4            |       11         |\n",
    "|      coins5       |        12         |        22            |       34         |\n",
    "|      coins6       |        11         |        21            |       32         |\n",
    "|      coins7       |        12         |        34            |       46         |\n",
    "|      coins8       |        12         |        34            |       46         |\n",
    "|      coins9       |        12         |        23            |       35         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_classification(img_in):\n",
    "    '''\n",
    "    \"Coin classification implementation\"\n",
    "    __Author__--Veljko Ilic, veljkoilic86@gmail.com\n",
    "    \n",
    "    Funkcija za ulaznu sliku na kojoj bi trebalo da budu novcici obradjuje tako da pre svega detektuje novcice i od \n",
    "    toga pravi binarnu masku pozivajuci fukciju coin_maks(img_in). Nakon sto se maska napravi poziva se funkcija poziva \n",
    "    fukciju za labeliranje povezanih regiona, a zatim se poziva ugradjena funkcija koja racuna povrsinu tih labeliranih \n",
    "    regiona i koja im nalazi centre jer je potrebno na svakom novcicu na ulaznoj slici ispisati kojoj klasi pripada.\n",
    "    \n",
    "    Inputs\n",
    "    img_in- Ulazna slika novcica\n",
    "    \n",
    "    Outputs\n",
    "    coins_number- Niz od dva elementa prvi je koliko ima novcica od jednog dinara, a drugi koliko ima novica od 5 dinara     \n",
    "    \n",
    "    Example\n",
    "    coin_number = coin_calssification(img_in)\n",
    "    '''\n",
    "    #If image is not given as parameter\n",
    "    if(img_in.size==0):\n",
    "        print(\"Morate proslediti sliku, prosledili ste prazan niz!\");\n",
    "        return False;\n",
    "    if(img_in.shape[0]==0 or img_in.shape[1]==0):\n",
    "        print(\"Slika mora biti prosledjena kao matrica koja ima visinu i sirinu razlicitu od nule!\")\n",
    "        return False;\n",
    "    \n",
    "    #creating arra of 2 elemnts to store coin number by class\n",
    "    coins_number = np.zeros(2);\n",
    "    #for input image creating binary mask\n",
    "    img_bin = coin_mask(img_in);\n",
    "    #for binry mask labelin conected components\n",
    "    bw_img  = bw_label(img_bin);\n",
    "    #measuring regions area\n",
    "    regions = skimage.measure.regionprops(bw_img);\n",
    "    \n",
    "    areas = [];\n",
    "    for i,region in zip(range(len(regions)), regions):\n",
    "            if(i!=0):\n",
    "                areas.append(region['Area'])\n",
    "    \n",
    "    areas.sort();\n",
    "    dif = 0;\n",
    "    max_gap = 0;\n",
    "    treshold = 0;\n",
    "    for i in range (0,len(areas)-1):\n",
    "        dif = areas[i+1]-areas[i];\n",
    "        if(dif>max_gap):\n",
    "            max_gap=dif;\n",
    "            treshold = areas[i];\n",
    "            \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 7), dpi=100);\n",
    "    \n",
    "    image_label_overlay = skimage.color.label2rgb(bw_img, image=img_in, bg_label=0);\n",
    "    ax.imshow(image_label_overlay, cmap='gray'), ax.set_title('Labelirana slika'), ax.axis('off')\n",
    "    \n",
    "    for i, region in zip(range(len(regions)), regions):\n",
    "        if(i!=0):\n",
    "            val = region['Area'];\n",
    "            if(val<=treshold):\n",
    "                coins_number[0] +=1;\n",
    "                val = 1\n",
    "            else:\n",
    "                coins_number[1] +=1;\n",
    "                val = 5;\n",
    "            ax.annotate(text=str(val), xy=(region['Centroid'][1], region['Centroid'][0]), xytext=(region['Centroid'][1], region['Centroid'][0]),\n",
    "                    horizontalalignment='center', verticalalignment='top', fontsize=12)\n",
    "\n",
    "    imsave('new_coin_count.jpg',image_label_overlay);\n",
    "    return coins_number;\n",
    "data_dir = 'sekvence/coins/';\n",
    "\n",
    "\n",
    "image = skimage.img_as_float((io.imread(os.path.join(data_dir, 'coins1.jpg'))));\n",
    "coins_number = coin_classification(image);\n",
    "print(coins_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sve obradjene slike na kojima je na novcicima ispisano kojim klasam pripadaju:\n",
    "\n",
    "\n",
    ">Slika 1\n",
    ">>![coins1](sekvence/1count.jpg)\n",
    "\n",
    ">Slika 2\n",
    ">>![coins2](sekvence/2count.jpg)\n",
    "\n",
    ">Slika 3\n",
    ">>![coins3](sekvence/3count.jpg)\n",
    "\n",
    ">Slika 4\n",
    ">>![coins4](sekvence/4count.jpg)\n",
    "\n",
    ">Slika 5\n",
    ">>![coins5](sekvence/5count.jpg)\n",
    "\n",
    ">Slika 6\n",
    ">>![coins6](sekvence/6count.jpg)\n",
    "\n",
    ">Slika 7\n",
    ">>![coins7](sekvence/7count.jpg)\n",
    "\n",
    ">Slika 8\n",
    ">>![coins8](sekvence/8count.jpg)\n",
    "\n",
    ">Slika 9\n",
    ">>![coins9](sekvence/9count.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
